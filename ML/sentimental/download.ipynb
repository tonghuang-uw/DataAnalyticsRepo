{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tonghuang/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from textblob import TextBlob, Word\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "# sklearn for feature extraction & modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from textacy.extract import ngrams, entitiespp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
      "\u001b[1m\n",
      "================= Installed pipeline packages (spaCy v3.7.2) =================\u001b[0m\n",
      "\u001b[38;5;4mℹ spaCy installation:\n",
      "/Users/tonghuang/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/spacy\u001b[0m\n",
      "\n",
      "NAME             SPACY            VERSION                            \n",
      "en_core_web_sm   >=3.7.2,<3.8.0   \u001b[38;5;2m3.7.1\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = 'Apple is looking at buying U.K. startup for $1 billion'\n",
    "doc = nlp(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>pos</th>\n      <th>tag</th>\n      <th>dep</th>\n      <th>shape</th>\n      <th>is_alpha</th>\n      <th>is_stop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Apple</td>\n      <td>Apple</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>nsubj</td>\n      <td>Xxxxx</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>is</td>\n      <td>be</td>\n      <td>AUX</td>\n      <td>VBZ</td>\n      <td>aux</td>\n      <td>xx</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>looking</td>\n      <td>look</td>\n      <td>VERB</td>\n      <td>VBG</td>\n      <td>ROOT</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>at</td>\n      <td>at</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>prep</td>\n      <td>xx</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>buying</td>\n      <td>buy</td>\n      <td>VERB</td>\n      <td>VBG</td>\n      <td>pcomp</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>U.K.</td>\n      <td>U.K.</td>\n      <td>PROPN</td>\n      <td>NNP</td>\n      <td>dobj</td>\n      <td>X.X.</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>startup</td>\n      <td>startup</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>dep</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>for</td>\n      <td>for</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>prep</td>\n      <td>xxx</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>$</td>\n      <td>$</td>\n      <td>SYM</td>\n      <td>$</td>\n      <td>quantmod</td>\n      <td>$</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>1</td>\n      <td>NUM</td>\n      <td>CD</td>\n      <td>compound</td>\n      <td>d</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>billion</td>\n      <td>billion</td>\n      <td>NUM</td>\n      <td>CD</td>\n      <td>pobj</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       text    lemma    pos  tag       dep  shape  is_alpha  is_stop\n0     Apple    Apple  PROPN  NNP     nsubj  Xxxxx      True    False\n1        is       be    AUX  VBZ       aux     xx      True     True\n2   looking     look   VERB  VBG      ROOT   xxxx      True    False\n3        at       at    ADP   IN      prep     xx      True     True\n4    buying      buy   VERB  VBG     pcomp   xxxx      True    False\n5      U.K.     U.K.  PROPN  NNP      dobj   X.X.     False    False\n6   startup  startup   NOUN   NN       dep   xxxx      True    False\n7       for      for    ADP   IN      prep    xxx      True     True\n8         $        $    SYM    $  quantmod      $     False    False\n9         1        1    NUM   CD  compound      d     False    False\n10  billion  billion    NUM   CD      pobj   xxxx      True    False"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[t.text, t.lemma_, t.pos_, t.tag_, t.dep_, t.shape_, t.is_alpha, t.is_stop]\n",
    "              for t in doc],\n",
    "             columns=['text', 'lemma', 'pos', 'tag', 'dep', 'shape', 'is_alpha', 'is_stop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./\")\n",
    "files = (DATA_DIR / 'bbc').glob('**/*.txt')\n",
    "bbc_articles = []\n",
    "doc_list = []\n",
    "for i, file in enumerate(files):\n",
    "    topic = file.parts[-2]\n",
    "    article = file.read_text(encoding='latin1').split('\\n')\n",
    "    heading = article[0].strip()\n",
    "    body = ' '.join([l.strip() for l in article[1:]]).strip()\n",
    "    doc_list.append([topic, heading, body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   topic    2225 non-null   object\n",
      " 1   heading  2225 non-null   object\n",
      " 2   body     2225 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 52.3+ KB\n"
     ]
    }
   ],
   "source": [
    "docs = pd.DataFrame(doc_list, columns=['topic', 'heading', 'body'])\n",
    "docs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic:\tTech\n",
      "\n",
      "Latest Opera browser gets vocal\n",
      "\n",
      "Net browser Opera 8.0, due for official release at the end of next month, will be \"the most accessible browser on the market\", according to its authors.  The latest version of the net browser can be controlled by voice command and will read pages aloud. The voice features, based on IBM technology, are currently only available in the Windows version. Opera can also magnify text by up to 10 times and users can create \"style sheets\", its developers say. This will enable them to view pages with colours and fonts that they prefer. But the browser does not yet work well with screen reader software often used by blind people, so its accessibility features are more likely to appeal to those with some residual vision. \"Our mission was always to provide the best internet experience for everyone,\" said Opera spokeswoman, Berit Hanson. \"So we would obviously not want to exclude disabled computer users.\"  Another feature likely to appeal to people with low vision is the ability to make pages fit to the screen width, which eliminates the need for horizontal scrolling.  The company points out that this will also appeal to anyone using Opera with a handheld device. The company says that features like voice activation are not solely aimed at visually impaired people. \"Our idea was to take a first step in making human-computer interaction more natural,\" said Ms Hanson. \"People are not always in a situation where they can access a keyboard, so this makes the web a more hands-free experience.\" Unlike commercially available voice recognition software, Opera does not have to be \"trained\" to recognise an individual voice. Around 50 voice commands are available and users will have to wear a headset which incorporates a microphone. The voice recognition function is currently only available in English. Opera is free to download but a paid-for version comes without an ad banner in the top right hand corner and with extra support. Opera began life as a research project - a spin-off from Norwegian telecoms company Telenor. Its browser is used by an estimated 10 million people on a variety of operating systems and a number of different platforms.\n"
     ]
    }
   ],
   "source": [
    "article = docs.sample(1).squeeze()\n",
    "print(f'Topic:\\t{article.topic.capitalize()}\\n\\n{article.heading}\\n')\n",
    "print(article.body.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('official', 'offici'),\n ('release', 'releas'),\n ('accessible', 'access'),\n ('according', 'accord'),\n ('its', 'it'),\n ('authors', 'author'),\n ('controlled', 'control'),\n ('voice', 'voic'),\n ('pages', 'page'),\n ('voice', 'voic'),\n ('features', 'featur'),\n ('based', 'base'),\n ('technology', 'technolog'),\n ('currently', 'current'),\n ('only', 'onli'),\n ('available', 'avail'),\n ('Windows', 'window'),\n ('magnify', 'magnifi'),\n ('times', 'time'),\n ('users', 'user'),\n ('create', 'creat'),\n ('sheets', 'sheet'),\n ('its', 'it'),\n ('developers', 'develop'),\n ('enable', 'enabl'),\n ('pages', 'page'),\n ('colours', 'colour'),\n ('fonts', 'font'),\n ('does', 'doe'),\n ('software', 'softwar'),\n ('used', 'use'),\n ('people', 'peopl'),\n ('its', 'it'),\n ('accessibility', 'access'),\n ('features', 'featur'),\n ('likely', 'like'),\n ('residual', 'residu'),\n ('always', 'alway'),\n ('provide', 'provid'),\n ('experience', 'experi'),\n ('everyone', 'everyon'),\n ('obviously', 'obvious'),\n ('exclude', 'exclud'),\n ('disabled', 'disabl'),\n ('computer', 'comput'),\n ('users', 'user'),\n ('Another', 'anoth'),\n ('feature', 'featur'),\n ('likely', 'like'),\n ('people', 'peopl'),\n ('ability', 'abil'),\n ('pages', 'page'),\n ('eliminates', 'elimin'),\n ('horizontal', 'horizont'),\n ('scrolling', 'scroll'),\n ('company', 'compani'),\n ('points', 'point'),\n ('anyone', 'anyon'),\n ('using', 'use'),\n ('device', 'devic'),\n ('company', 'compani'),\n ('says', 'say'),\n ('features', 'featur'),\n ('voice', 'voic'),\n ('activation', 'activ'),\n ('solely', 'sole'),\n ('aimed', 'aim'),\n ('visually', 'visual'),\n ('impaired', 'impair'),\n ('people', 'peopl'),\n ('making', 'make'),\n ('human-computer', 'human-comput'),\n ('interaction', 'interact'),\n ('natural', 'natur'),\n ('People', 'peopl'),\n ('always', 'alway'),\n ('situation', 'situat'),\n ('makes', 'make'),\n ('hands-free', 'hands-fre'),\n ('experience', 'experi'),\n ('Unlike', 'unlik'),\n ('commercially', 'commerci'),\n ('available', 'avail'),\n ('voice', 'voic'),\n ('recognition', 'recognit'),\n ('software', 'softwar'),\n ('does', 'doe'),\n ('trained', 'train'),\n ('recognise', 'recognis'),\n ('individual', 'individu'),\n ('voice', 'voic'),\n ('voice', 'voic'),\n ('commands', 'command'),\n ('available', 'avail'),\n ('users', 'user'),\n ('incorporates', 'incorpor'),\n ('microphone', 'microphon'),\n ('voice', 'voic'),\n ('recognition', 'recognit'),\n ('currently', 'current'),\n ('only', 'onli'),\n ('available', 'avail'),\n ('comes', 'come'),\n ('telecoms', 'telecom'),\n ('company', 'compani'),\n ('Its', 'it'),\n ('used', 'use'),\n ('estimated', 'estim'),\n ('people', 'peopl'),\n ('variety', 'varieti'),\n ('operating', 'oper'),\n ('systems', 'system'),\n ('different', 'differ'),\n ('platforms', 'platform')]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "parsed_body = TextBlob(article.body)\n",
    "[(word, stemmer.stem(word)) for i, word in enumerate(parsed_body.words) \n",
    " if word.lower() != stemmer.stem(parsed_body.words[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/tonghuang/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('its', 'it'),\n ('authors', 'author'),\n ('pages', 'page'),\n ('features', 'feature'),\n ('times', 'time'),\n ('users', 'user'),\n ('sheets', 'sheet'),\n ('its', 'it'),\n ('developers', 'developer'),\n ('pages', 'page'),\n ('colours', 'colour'),\n ('fonts', 'font'),\n ('does', 'doe'),\n ('its', 'it'),\n ('features', 'feature'),\n ('was', 'wa'),\n ('users', 'user'),\n ('pages', 'page'),\n ('points', 'point'),\n ('says', 'say'),\n ('features', 'feature'),\n ('was', 'wa'),\n ('makes', 'make'),\n ('does', 'doe'),\n ('commands', 'command'),\n ('users', 'user'),\n ('comes', 'come'),\n ('as', 'a'),\n ('telecoms', 'telecom'),\n ('systems', 'system'),\n ('platforms', 'platform')]"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(word, word.lemmatize()) for i, word in enumerate(parsed_body.words) \n",
    " if word != parsed_body.words[i].lemmatize()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Sentiment(polarity=0.18816326530612246, subjectivity=0.439591836734694)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_body.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<style type=\"text/css\">\n</style>\n<table id=\"T_5a2f4\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_5a2f4_level0_col0\" class=\"col_heading level0 col0\" >count</th>\n    </tr>\n    <tr>\n      <th class=\"index_name level0\" >topic</th>\n      <th class=\"blank col0\" >&nbsp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_5a2f4_level0_row0\" class=\"row_heading level0 row0\" >sport</th>\n      <td id=\"T_5a2f4_row0_col0\" class=\"data row0 col0\" >22.97%</td>\n    </tr>\n    <tr>\n      <th id=\"T_5a2f4_level0_row1\" class=\"row_heading level0 row1\" >business</th>\n      <td id=\"T_5a2f4_row1_col0\" class=\"data row1 col0\" >22.92%</td>\n    </tr>\n    <tr>\n      <th id=\"T_5a2f4_level0_row2\" class=\"row_heading level0 row2\" >politics</th>\n      <td id=\"T_5a2f4_row2_col0\" class=\"data row2 col0\" >18.74%</td>\n    </tr>\n    <tr>\n      <th id=\"T_5a2f4_level0_row3\" class=\"row_heading level0 row3\" >tech</th>\n      <td id=\"T_5a2f4_row3_col0\" class=\"data row3 col0\" >18.02%</td>\n    </tr>\n    <tr>\n      <th id=\"T_5a2f4_level0_row4\" class=\"row_heading level0 row4\" >entertainment</th>\n      <td id=\"T_5a2f4_row4_col0\" class=\"data row4 col0\" >17.35%</td>\n    </tr>\n  </tbody>\n</table>\n",
      "text/plain": "<pandas.io.formats.style.Styler at 0x14e530390>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.topic.value_counts(normalize = True).to_frame('count').style.format({'count': '{:.2%}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 64-bit ('nlp': conda)",
   "name": "python3117jvsc74a57bd061144442c5bba5d28851d4d88bd107affeefd4f9a3e21babceae053099746efa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "61144442c5bba5d28851d4d88bd107affeefd4f9a3e21babceae053099746efa"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}